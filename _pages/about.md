---
permalink: /
title: # "Academic Pages is a ready-to-fork GitHub Pages template for academic personal websites"
author_profile: true
redirect_from: 
  - /about/
  - /about.html
---

I am a Research Scientist at LG AI Research. I received my PhD from the Computer Science Department at the University of Michigan. My research interests lie in Machine Learning and Natural Language Processing. My specific interests include representation learning, learning from limited supervision and language grounding.

News
- 03/13/24: 3 papers accepted at NAACL 2024
- 10/10/23: Invited talk at UM on Task Planning with Language Models
- 10/07/23: 4 papers accepted at EMNLP 2023
- 05/02/23: 3 papers accepted at ACL 2023

Talks
- May 2024: Guiding Language Models to be Better Agents (Frontiers of AI in Business and Society @ UIC)
- Oct 2023: Task Planning with Large Language Models (University of Michigan AI Seminar)
- Jul 2022: Few-Shot Subgoal Planning with Language Models (Talk starts 49:16)
- Aug 2019: Zero-Shot Entity Linking by Reading Entity Descriptions
- Feb 2019: Ann Arbor Deep Learning Event

Selected Publications

- Code Models are Zero-shot Precondition Reasoners
  Lajanugen Logeswaran, Sungryull Sohn, Yiwei Lyu, Anthony Zhe Liu, Dong-Ki Kim, Dongsub Shim, Moontae Lee, Honglak Lee
  NAACL 2024 (Also at Neurips FMDM Workshop 2023)


- Understanding the Capabilities and Limitations of Large Language Models for Cultural Commonsense
  Siqi Shen, Lajanugen Logeswaran, Moontae Lee, Honglak Lee, Soujanya Poria, Rada Mihalcea
  NAACL 2024 (Social Impact Award)


- TOD-Flow: Modeling the Structure of Task-Oriented Dialogues
  Sungryull Sohn, Yiwei Lyu, Anthony Zhe Liu, Lajanugen Logeswaran, Dong-Ki Kim, Dongsub Shim, Honglak Lee
  EMNLP 2023

- Unsupervised Task Graph Generation from Instructional Video Transcripts
  Lajanugen Logeswaran, Sungryull Sohn, Yunseok Jang, Moontae Lee, Honglak Lee
  Findings of ACL 2023
  Also at ACL WNU Workshop 2023

- Knowledge Unlearning for Mitigating Privacy Risks in Language Models
  Joel Jang, Dongkeun Yoon, Sohee Yang, Sungmin Cha, Moontae Lee, Lajanugen Logeswaran, Minjoon Seo
  ACL 2023

- Exploring the Benefits of Training Expert Language Models over Instruction Tuning
  Joel Jang, Seungone Kim, Seonghyeon Ye, Doyoung Kim, Lajanugen Logeswaran, Moontae Lee, Kyungjae Lee, Minjoon Seo
  ICML 2023

- Few-shot Subgoal Planning with Language Models
  Lajanugen Logeswaran, Violet Fu, Moontae Lee, Honglak Lee
  NAACL 2022
  Also at ACL CSRR workshop 2022

- Zero-Shot Entity Linking by Reading Entity Descriptions
  Lajanugen Logeswaran, Ming-Wei Chang, Kenton Lee, Kristina Toutanova, Jacob Devlin, Honglak Lee
  ACL 2019
  Nominated for best paper

- Content Preserving Text Generation with Attribute Controls
  Lajanugen Logeswaran, Honglak Lee, Samy Bengio
  NIPS 2018

- An Efficient Framework for Learning Sentence Representations
  Lajanugen Logeswaran, Honglak Lee
  ICLR 2018

- Sentence Ordering and Coherence Modeling using Recurrent Neural Networks
  Lajanugen Logeswaran, Honglak Lee, Dragomir Radev
  AAAI 2018

- Generative Adversarial Text-to-Image Synthesis
  Scott Reed, Zeynep Akata, Xinchen Yan, Lajanugen Logeswaran, Bernt Schiele, Honglak Lee
  ICML 2016

Professional Experience
- Research Scientist, LG AI Research (Ann Arbor), Jul 2021 - Present
- Research Intern, Facebook AI Research (New York), May - Aug 2019
- Research Intern, Google Research (Seattle), May 2018 - Jan 2019
- Research Intern, Google Brain (Mountain View), Feb - Jun 2017

Awards & Honors
- IEEEXtreme 24 hour Programming Competition - 24th place (2013)
- INexus International Robot Competition - 3rd place (2012)
- Bronze medal at the 50th International Mathematical Olympiad (2009)
- Gold medal at Sri Lankan Mathematics Olympiad (2007)
